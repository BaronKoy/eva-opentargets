# Setting up the common environment 

Log in to the LSF cluster, where all data processing must take place. Switch to a common EVA production user instead of your personal account. Then adjust and execute the commands below. They will set up the environment, fetch and build the code.

Notes:
* The first five variables are installation-specific and are blanked in this repository. You can get the values for the EVA use case from the [private repository](https://github.com/EBIvariation/configuration/blob/master/open-targets-configuration.md).
* By modifying the `*REMOTE` and `*BRANCH` variables, you can run arbitrary versions of both the main and the VEP pipeline. This is highly useful for development and debugging. By default it fetches master branches of both repositories.

```bash
# This variable should point to the directory where the clone of this repository is located on the cluster
export CODE_ROOT=

# Location of Python installation which you configured using build instructions
export PYTHON_INSTALL_PATH=

# Location of bcftools installation path
export BCFTOOLS_INSTALL_PATH=

# The directory where subdirectories for each batch will be created
export BATCH_ROOT_BASE=

# Base path of FTP directory on the cluster
export FTP_PATH_BASE=

# Base bsub command line for all commands.
export BSUB_CMDLINE="bsub"

# Setting up Python paths
export PATH=${PYTHON_INSTALL_PATH}:${PYTHON_INSTALL_PATH}/bin:${BCFTOOLS_INSTALL_PATH}:$PATH
export PYTHONPATH=${PYTHON_INSTALL_PATH}

# External service paths
CLINVAR_PATH_BASE="ftp://ftp.ncbi.nlm.nih.gov/pub/clinvar"

export MAIN_REMOTE=origin
export MAIN_BRANCH=master
export VEP_REMOTE=origin
export VEP_BRANCH=master

cd ${CODE_ROOT}
git fetch ${MAIN_REMOTE}
git checkout ${MAIN_BRANCH}
git reset --hard ${MAIN_REMOTE}/${MAIN_BRANCH}

git submodule update --init --recursive
cd vep-mapping-pipeline
git fetch ${VEP_REMOTE}
git checkout ${VEP_BRANCH}
git reset --hard ${VEP_REMOTE}/${VEP_BRANCH}
cd ..

python3 setup.py install
```

# Additional instructions for special cases (doesn't need to be run every time)

The pipeline requires Python version 3.8.

## Python 3.8 installation (optional)
The instructions in this section will be useful:
* If you have a different version of Python and want to install Python 3.8 without replacing your default `python` / `python3` executables;
* If you are running the pipeline on the `ebi-cli` cluster, which currently only supports Python 3.4.

Adjust `VERSION` and `INSTALL_PATH` if needed.

```bash
VERSION=3.8.1
INSTALL_PATH=/nfs/production3/eva/software/python-${VERSION}
mkdir -p ${INSTALL_PATH}
cd ${INSTALL_PATH}
wget https://www.python.org/ftp/python/${VERSION}/Python-${VERSION}.tgz
tar zxfv Python-${VERSION}.tgz
mv Python-${VERSION}/* .
rmdir Python-${VERSION}
ln -s python python3
chmod a+x python python3
```

### Root installation
This way is easier as it doesn't require you to set up any paths manually. Package installation is also less likely to go wrong if you're using this way.

You need to have zlib development headers installed. Command for Debian/Ubuntu is `sudo apt-get -y install zlib1g-dev`.

```bash
./configure --with-zlib=/usr/include --enable-optimizations
make -j `nproc` altinstall
```

You can now invoke the new installation as `python3.8`.

### Non-root installation
This is the only way which will work on the `ebi-cli` cluster. It is also useful if you need to have more than one minor version installed simultaneously, e. g. Python 3.8.0 and 3.8.1.
```bash
./configure --prefix=${INSTALL_PATH}
make -j `nproc`
make -j `nproc` install
```

You can invoke this installation by using a direct path, `${INSTALL_PATH}/python`. In order to temporarily set it as default (and invoke simply as `python`), configure the paths:
```bash
export PATH=${INSTALL_PATH}:${INSTALL_PATH}/bin:$PATH
export PYTHONPATH=${INSTALL_PATH}
```

The installed Python version can then be called with either `python` or `python3`. You can also use either `pip` or `pip3` to install packages into this local distribution. It makes sense to install some packages straight away:
```bash
pip3 install --upgrade pip
pip3 install --upgrade numpy pandas scipy
```

## Building Java ClinVar parser
The parser is used during the first stage of the pipeline to parse XML files provided by ClinVar and extract the required information. The parser files are autogenerated using the JAXB framework.

```bash
cd clinvar-xml-parser
mvn package
```

Two JAR files will be generated in the 'target' directory, one of them including all the dependencies.

## Deploying local OLS installation
During the preparation of 2019_04 release, which had to be synchronized with EFO v3, OLS had to be deployed locally because the production deployment of OLS on www.ebi.ac.uk/ols only supported EFO v2 at the time. This can be done using the following command (substitute the image version as appropriate):

```bash
sudo docker run -p 8080:8080 simonjupp/efo3-ols:3.4.0
```

To use the local deployment, uncomment the configuration section at the top of `/eva_cttv_pipeline/trait_mapping/ols.py` to specify the URL of the local installation. If you have deployed OLS on the different machine than the one you're using to run the pipeline, substitute the correct IP address of the machine where the OLS installation is deployed.

Please contact the semantic data integration team at [SPOT](https://www.ebi.ac.uk/about/spot-team) if you have questions about local OLS installation.

## Building the pipeline and (optionally) setting up virtual environment
1. `git clone --recursive git@github.com:EBIvariation/eva-cttv-pipeline.git`
2. `cd eva-cttv-pipeline`
3. [OPTIONAL] `virtualenv -p python3.8 venv`
4. [OPTIONAL] `source venv/bin/activate` (`venv/bin/deactivate` to deactivate virtualenv)
5. `pip install -r requirements.txt`
6. And then one of:
   * To install: `python3 setup.py install`
   * To install to develop: `python3 setup.py develop`
   * To build a source distribution: `python3 setup.py sdist`

## Tests
You can run all tests with: `python3 setup.py test`
